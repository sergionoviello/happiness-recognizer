{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer vision\n",
    "\n",
    "let's say we have an image 6x6 pixels in rgb so with 3 channels. \n",
    "We apply a 3x3 filter which also has to have the same number of channels (3). \n",
    "The filter is a matrix of (0, 1, -1) to turn on and off some features, like edge detection.\n",
    "We can imagine to put the filter represented as cube on top of the image. We multiply each number in each cell of the filter with the one on the image for each of the 3 channels and then we sum them up. The result is the number of the 1st cell in the output image. \n",
    "We then slide the filter by 1 position and repeat the multiply and sum to get the number in the second cell of the output image. \n",
    "The output image will have a dimension of 4x4x3. (the formula is (width image + 2padding - width filter)/stride + 1 => (6+0-3+1)/1=4)\n",
    "\n",
    "![alt text](sc1.png \"single filter\")\n",
    "\n",
    "Of course we can apply multiple filters. So we will have an output image for each filter that we can stack together. \n",
    "\n",
    "![alt text](sc2.png \"multiple filters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](sc3.png \"convnet\")\n",
    "\n",
    "\n",
    "In the example we have an image of 39x39. We apply 10 filters of dimension 3x3x3 using no padding and stride 1. \n",
    "Then we apply other 20 filters of size 5x5x3 with no padding and stride 2. \n",
    "Finally we apply 40 filters of size 5x5x3 with no padding and stride 2. \n",
    "We end up with an output imasge of 7x7x40.\n",
    "We can then flat this volume into a long vector and input it in an activation layer, like sigmoid layer, which will return 0 or 1. This way we can classify if the image is happy or not happy. \n",
    "\n",
    "Other than convolutional layers we use other layers like a pooling layer. \n",
    "\n",
    "![alt text](sc4.png \"max pooling\")\n",
    "\n",
    "let's say we have an image of size 4x4. We can apply a filter of max pooling of size 2 and stride 2. For each of sub-sections we need to find the max value. \n",
    "There are other pooling layers similar like the average pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](sc5.png \"another example\")\n",
    "\n",
    "In this example of hand-writing recongnition the input image is 32x32x3. \n",
    "The 1st layer is a convolutional layer + max pooling \n",
    "The 2nd layer is a convolutional layer + max pooling \n",
    "The 3rd is a fully connected layer where each neuron of the prev layer is connected to the next with matrix multiplication and adding biases. \n",
    "The 4th is another fully connected layer\n",
    "The last is a softmax layer that outputs a vector of size 10 which will encode what number is predicted. For example 7 could be [0 0 0 0 0 0 1 0 0 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "parentPath = os.path.abspath(\"..\")\n",
    "if parentPath not in sys.path:\n",
    "    sys.path.insert(0, parentPath)\n",
    "\n",
    "from happiness_recognizer import HappinessRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64, 64, 3)         12        \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 70, 70, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 64, 64, 12)        1776      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 64, 64, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 28, 28, 32)        9632      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 17,869\n",
      "Trainable params: 17,781\n",
      "Non-trainable params: 88\n",
      "_________________________________________________________________\n",
      "150/150 [==============================] - 0s     \n",
      "\n",
      "Loss = 0.0690369531512\n",
      "Test Accuracy = 0.979999997616\n"
     ]
    }
   ],
   "source": [
    "happiness = HappinessRecognizer('static/uploads/cry.jpg')\n",
    "results = happiness.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Happy\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
